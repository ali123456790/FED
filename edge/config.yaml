# Server configuration
server:
  address: "0.0.0.0"
  port: 8080
  rounds: 10
  min_clients: 2
  min_available_clients: 2
  timeout: 60
  aggregation_strategy: "fedavg"  # Options: fedavg, fedprox, fedopt

# Client configuration
client:
  local_epochs: 5
  batch_size: 32
  learning_rate: 0.001
  optimizer: "adam"
  device_heterogeneity: true
  resource_monitoring: true

# Edge configuration
edge:
  enabled: true
  nodes: 3
  aggregation_strategy: "weighted_average"
  client_assignment: "proximity"  # Options: proximity, resource, random, static
  base_port: 8090
  forward_frequency: 1  # Forward to server every N rounds
  min_clients: 1  # Minimum clients required to start edge server
  min_available_clients: 1  # Minimum clients that must be available for training
  fraction_fit: 1.0  # Fraction of clients to select for training
  fraction_evaluate: 1.0  # Fraction of clients to select for evaluation

# Security configuration
security:
  differential_privacy:
    enabled: true
    noise_multiplier: 1.0
    l2_norm_clip: 1.0
  encryption:
    enabled: true
    type: "tls"  # Options: tls, custom
  secure_aggregation:
    enabled: true
    type: "secure_sum"  # Options: secure_sum, robust_aggregation
  threat_model:
    poisoning_defense: true
    adversarial_defense: true

# Evaluation configuration
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1", "auc"]
  privacy_analysis: true
  comparison_with_centralized: true
  visualization: true

# Logging configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "./logs/fids.log"
  console: true

# Data configuration
data:
  dataset: "n_baiot"
  path: "./data/raw"
  test_size: 0.2
  validation_size: 0.1
  iid: false
  feature_selection: true
  num_features: 10

# Model configuration
model:
  type: "deep_learning"  # Options: traditional, deep_learning
  name: "lstm"  # Options: random_forest, naive_bayes, lstm, bilstm
  hyperparameters:
    random_forest:
      n_estimators: 100
      max_depth: 10
    naive_bayes:
      var_smoothing: 1e-9
    lstm:
      hidden_size: 128
      num_layers: 2
      dropout: 0.2
    bilstm:
      hidden_size: 128
      num_layers: 2
      dropout: 0.2